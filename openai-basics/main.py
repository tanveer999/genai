import tiktoken
from openai import OpenAI

client = OpenAI(
  base_url="http://localhost:1234/v1",
  api_key="lm-studio"
)
MODEL = "google/gemma-3-4b"

def tokenization():
  text = f"""
    Jupiter is the fifth planet from the Sun and the \
    largest in the Solar System. It is a gas giant with \
    a mass one-thousandth that of the Sun, but two-and-a-half \
    times that of all the other planets in the Solar System combined. \
    Jupiter is one of the brightest objects visible to the naked eye \
    in the night sky, and has been known to ancient civilizations since \
    before recorded history. It is named after the Roman god Jupiter.[19] \
    When viewed from Earth, Jupiter can be bright enough for its reflected \
    light to cast visible shadows,[20] and is on average the third-brightest \
    natural object in the night sky after the Moon and Venus.
  """

  encoding = tiktoken.encoding_for_model("gpt-4o")

  tokens = encoding.encode(text)
  print(f"Tokens: {tokens}")

  # decode tokens
  decoded_tokens = [encoding.decode_single_token_bytes(token).decode('utf-8') for token in tokens]
  print(f"Decoded tokens: {decoded_tokens}")

def main1():
  tokenization()

def get_completion(prompt):
  messages = [{"role": "user", "content": prompt}]

  response = client.chat.completions.create(
    model=MODEL,
    messages=messages,
    temperature=0.1,
    max_tokens=1000
  )

  return response.choices[0].message.content

def get_completion_with_streaming(prompt):
  """
  This function should print the response as it is being generated by the model. 
  """
  messages = [{"role": "user", "content": prompt}]

  response = client.chat.completions.create(
    model=MODEL,
    messages=messages,
    temperature=0.1,
    max_tokens=1000,
    stream=True
  )

  full_response = []
  for chunk in response:
    delta = chunk.choices[0].delta.content
    if delta:
      print(delta, end="", flush=True)
      full_response.append(delta)

  print()
  return "".join(full_response)

def main2():
  text = "What is the capital of France?"
  response = get_completion(text)
  print(response)

def main3():
  # fabrication
  text = "Tell me about civil war of 2076"
  response = get_completion(text)
  print(response)

def main4():
  text = "What is the capital of France?"
  get_completion_with_streaming(text)

if __name__ == "__main__":
  main4()